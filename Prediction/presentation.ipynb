{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1=pd.read_pickle('df_llll.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0.1', 'Unnamed: 0.1.1', 'business_id', 'cool', 'date',\n",
      "       'funny', 'review_id', 'stars', 'text', 'type', 'useful', 'user_id',\n",
      "       'year', 'month', 'label', 'filtered_text', 'lemmatize_text',\n",
      "       'lemmatize_filtered_text', 'review_all_length',\n",
      "       'review_exceptstop_length', 'noun', 'adj', 'adv', 'verb',\n",
      "       'simple_words', 'complex_words', 'syllables', 'num_sentence',\n",
      "       'error_num', 'fog_index', 'Flesch_reading_ease_score', 'SMOG_index',\n",
      "       'fog_index_simple', 'word_length', 'business_star',\n",
      "       'business_review_count', 'city', 'user_average_stars', 'user_fans',\n",
      "       'user_friends', 'user_received_funny', 'user_received_cool',\n",
      "       'user_received_useful', 'sentiment_score', 'environment_score',\n",
      "       'other_score', 'price_score', 'food_score', 'service_score', 'ex_id',\n",
      "       'useful_label', 'BOW', 'business_avg_star', 'star_deviation',\n",
      "       'user_days_since', 'argumentation_result', 'index', 'fact', 'value',\n",
      "       'testimony', 'policy', 'evidence_reson', 'not_evidence_reason',\n",
      "       'evidence_reason', 'relation_ratio', 'value_ratio', 'testimony_ratio',\n",
      "       'policy_ratio', 'fact_ratio'],\n",
      "      dtype='object')\n",
      "69\n"
     ]
    }
   ],
   "source": [
    "print(df1.columns)\n",
    "print(len(df1.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2=pd.read_pickle('data_with_op.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['business_id', 'cool', 'date', 'funny', 'review_id', 'stars', 'text',\n",
      "       'type', 'useful', 'user_id', 'year', 'month', 'label', 'filtered_text',\n",
      "       'lemmatize_text', 'lemmatize_filtered_text', 'BOW', 'sentiment_score',\n",
      "       'noun', 'adj', 'adv', 'verb', 'review_all_length',\n",
      "       'review_exceptstop_length', 'simple_words', 'complex_words',\n",
      "       'syllables', 'num_sentence', 'error_num', 'fog_index',\n",
      "       'Flesch_reading_ease_score', 'SMOG_index', 'fog_index_simple',\n",
      "       'word_length', 'business_avg_star', 'business_star',\n",
      "       'business_review_count', 'city', 'user_average_stars', 'user_fans',\n",
      "       'user_friends', 'user_received_funny', 'user_received_cool',\n",
      "       'user_received_useful', 'user_days_since', 'star_deviation',\n",
      "       'environment_score', 'mean_environment_score', 'other_score',\n",
      "       'mean_other_score', 'price_score', 'mean_price_score', 'food_score',\n",
      "       'mean_food_score', 'service_score', 'mean_service_score'],\n",
      "      dtype='object')\n",
      "56\n"
     ]
    }
   ],
   "source": [
    "print(df2.columns)\n",
    "print(len(df2.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for column in ['fact', 'value','testimony', 'policy', 'evidence_reson', 'not_evidence_reason',\n",
    "       'evidence_reason', 'relation_ratio', 'value_ratio', 'testimony_ratio',\n",
    "       'policy_ratio', 'fact_ratio']:\n",
    "    df2[column]=df2.review_id.map(df1[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['business_id', 'cool', 'date', 'funny', 'review_id', 'stars', 'text',\n",
      "       'type', 'useful', 'user_id', 'year', 'month', 'label', 'filtered_text',\n",
      "       'lemmatize_text', 'lemmatize_filtered_text', 'BOW', 'sentiment_score',\n",
      "       'noun', 'adj', 'adv', 'verb', 'review_all_length',\n",
      "       'review_exceptstop_length', 'simple_words', 'complex_words',\n",
      "       'syllables', 'num_sentence', 'error_num', 'fog_index',\n",
      "       'Flesch_reading_ease_score', 'SMOG_index', 'fog_index_simple',\n",
      "       'word_length', 'business_avg_star', 'business_star',\n",
      "       'business_review_count', 'city', 'user_average_stars', 'user_fans',\n",
      "       'user_friends', 'user_received_funny', 'user_received_cool',\n",
      "       'user_received_useful', 'user_days_since', 'star_deviation',\n",
      "       'environment_score', 'mean_environment_score', 'other_score',\n",
      "       'mean_other_score', 'price_score', 'mean_price_score', 'food_score',\n",
      "       'mean_food_score', 'service_score', 'mean_service_score', 'fact',\n",
      "       'value', 'testimony', 'policy', 'evidence_reson', 'not_evidence_reason',\n",
      "       'evidence_reason', 'relation_ratio', 'value_ratio', 'testimony_ratio',\n",
      "       'policy_ratio', 'fact_ratio'],\n",
      "      dtype='object')\n",
      "68\n"
     ]
    }
   ],
   "source": [
    "print(df2.columns)\n",
    "print(len(df2.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Traditional_features=['review_all_length','stars',\n",
    "                      'review_exceptstop_length','num_sentence',\n",
    "                       'noun', 'adj', 'adv', 'verb','sentiment_score','BOW']\n",
    "Readability_features=['error_num','fog_index','Flesch_reading_ease_score',\n",
    "                     'SMOG_index','fog_index_simple','word_length']\n",
    "Business_features=['business_review_count','business_avg_star', 'star_deviation','business_star']\n",
    "Reviewer_features=['user_average_stars', 'user_fans', 'user_received_funny', 'user_received_cool',\n",
    "       'user_received_useful','user_days_since','month']\n",
    "Aspect_features=['environment_score', 'food_score', 'service_score','other_score','price_score']\n",
    "Argumentation_features=[ \n",
    "        #'fact', 'value',\n",
    "       #'testimony', 'policy',  \n",
    "        'not_evidence_reason',\n",
    "       'evidence_reason', 'relation_ratio', 'value_ratio', 'testimony_ratio',\n",
    "       'policy_ratio', 'fact_ratio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "###report result \n",
    "def report(results, n_top=1):\n",
    "    for i in range(1, n_top+1):\n",
    "        feature_combination = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for feature in feature_combination:\n",
    "            print(\"best model\")\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][feature],\n",
    "                  results['std_test_score'][feature]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][feature]))\n",
    "    return results['mean_test_score'][feature]\n",
    "\n",
    "def main(df,features):\n",
    "    final_result={}\n",
    "    start = time()\n",
    "    print('Run ')\n",
    "    param_dist = { 'max_depth':range(3,14,2),\n",
    "             'min_samples_split':range(800,1900,200),}\n",
    "    n_iter_search = 20\n",
    "    clf = GradientBoostingClassifier(learning_rate=0.1,n_estimators=40)\n",
    "    random_search = RandomizedSearchCV(clf, param_distributions=param_dist,\n",
    "                                   n_iter=n_iter_search,scoring='f1')\n",
    "    random_search.fit(df[features], df['label'])\n",
    "    print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "          \" parameter settings.\" % ((time() - start), n_iter_search))\n",
    "    print(\"GBDT:\")\n",
    "    final_result['GBDT']=report(random_search.cv_results_)\n",
    "    #print('Cost time:',time()-start)\n",
    "    print(\"finish:GBDT\")\n",
    "    \n",
    "    \n",
    "    param_dist = {'kernel': ['rbf'], 'gamma': [1e-4,1e-5],\n",
    "                     'C': [0.05,0.1,0.2,0.5,1,2]}\n",
    "    # run randomized search\n",
    "    n_iter_search = 10\n",
    "    clf = svm.SVC()\n",
    "    random_search = RandomizedSearchCV(clf, param_distributions=param_dist,\n",
    "                                   n_iter=n_iter_search,scoring='f1')\n",
    "    \n",
    "    start = time()\n",
    "    random_search.fit(df[features], df['label'])\n",
    "    #print('SVM')\n",
    "    print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time() - start), n_iter_search))\n",
    "    print('SVM:')\n",
    "    final_result['SVM']=report(random_search.cv_results_)\n",
    "    \n",
    "    print('finish SVM')\n",
    "    param_dist = {\n",
    "        \"max_depth\": [3, None],\n",
    "              \"min_samples_split\": sp_randint(2, 15),\n",
    "              \"min_samples_leaf\": sp_randint(1, 11),\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "    # run randomized search\n",
    "    n_iter_search = 20\n",
    "    clf = RandomForestClassifier(n_estimators=40)\n",
    "    random_search = RandomizedSearchCV(clf, param_distributions=param_dist,\n",
    "                                   n_iter=n_iter_search,scoring='f1')\n",
    "    \n",
    "    start = time()\n",
    "    random_search.fit(df[features], df['label'])\n",
    "    \n",
    "    print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time() - start), n_iter_search))\n",
    "    print('Random Forest')\n",
    "    final_result['RF']=report(random_search.cv_results_)  \n",
    "    print('finish Random Forest')\n",
    "    return final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ALL_except_ABO=Traditional_features+Readability_features+Business_features+Reviewer_features+Argumentation_features\n",
    "ALL_except_ABF=Traditional_features+Readability_features+Business_features+Reviewer_features+Aspect_features\n",
    "ALL=ALL_except_ABF+Argumentation_features\n",
    "from tqdm import tqdm\n",
    "df_test=pd.DataFrame([\n",
    "['Baseline',Traditional_features],\n",
    "           ['Baseline+RF',Traditional_features+Readability_features],\n",
    "           ['Baseline+BF',Traditional_features+Business_features],\n",
    "            ['Baseline+RF',Traditional_features+Reviewer_features],\n",
    "          ['Baseline+ABO',Traditional_features+Aspect_features],\n",
    "           ['Baseline+ABF',Traditional_features+Argumentation_features],\n",
    "             ['Baseline+ALL-ABO',ALL_except_ABO],\n",
    "             ['Baseline+ALL-ABF',ALL_except_ABF],\n",
    "                     ['Baseline+ALL',ALL]],columns=['model','feature_group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/9 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run \n",
      "RandomizedSearchCV took 20.35 seconds for 20 candidates parameter settings.\n",
      "GBDT:\n",
      "best model\n",
      "Mean validation score: 0.658 (std: 0.007)\n",
      "Parameters: {'min_samples_split': 1800, 'max_depth': 3}\n",
      "finish:GBDT\n"
     ]
    }
   ],
   "source": [
    "df_test['F1-score']=[main(df2,i) for i in tqdm(df_test.feature_group)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in df_test.index:\n",
    "    print(df_test.ix[i].model,'SVM:','%.5f' % df_test.ix[i]['F1-score']['SVM'],\n",
    "         'GBDT:','%.5f' % df_test.ix[i]['F1-score']['GBDT'],\n",
    "          'RF:','%.5f' % df_test.ix[i]['F1-score']['RF'])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
